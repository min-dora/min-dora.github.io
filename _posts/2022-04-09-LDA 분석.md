---
date: 2022-04-08
title: "LDA(Latent Dirichlet Allocation)분석"
categories: Python
tags: 
- Python


toc: true  
toc_sticky: true 
author_profile: true
---

## 패키지 불러오기
```
import easygui
import numpy as np
import pandas as pd
import re
import matplotlib.pyplot as plt
```


* ## encoding 형식에 맞춰서 파일 저장

  - encoding은 CP949 외 __"UTF-8"__ 도 자주 사용됨
```
data = pd.read_csv(eg.fileopenbox(), encoding="CP949")
data
```



* ## #한 시트에 데이터가 다 안들어갈 경우 -> 파일 안에 있는 시트 전체 적용방법

```
df_all = pd.read_excel("eg.fileopenbox()", sheet_name = None)
data = pd.concat(df_all, ignore_index = True)
data
```

```
data_text = data.전체_연관어.astype("str") # 문자열
data_text
```




* ## 데이터 토큰화

```
data_list = []
for x in data_text:
    data_list.append(x.split(','))

data_list    
```


  - 데이터 제거 리스트 만들기 및 제거리스트 외 데이터 불러오기
```
lis = ['하나','둘', '셋', '']
data_list = [[word for word in x if word not in lis] # 20200408_ 대괄호 맺음이 없는데 맞는지 확인하기
             for x in data_list]
data_list
```


  - 'no_below'가 빈도수 제한 파라미터로 추정됨


```
high_score_reviews = data_list # 전처리한 데이터 넣기(연관어면 연관어 선언 변수)

high_score_reviews = [[y for y in x if not len(y)==1] # 1글자 제거
                     for x in high_score_reviews] # 20200408_ 대괄호 맺음이 없는데 맞는지 확인하기

dictionary = corpora.Dictionary(high_score_reviews)
dictionary.filter_extremes(no_below = 10) #10회 이하로 등장한 단어는 삭제 
corpus = [dictionary.doc2bow(text) for text in high_score_reviews]
```



* ## LDA 분석


- 패키지 불러오기
```
import matplotlib.pyplot as plt
from gensim.models import CoherenceModel
```


> ## Perplexity, Coherence


⭐ |Perplexity | Coherence
---------|----------|---------
 의미 | 확률 모델이 결과를 얼마나 정확하게 예측하는지.<br> 낮을수록 정확하게 예측. | 토픽이 얼마나 의미론적으로 일관성 있는지. <br>높을수록 의미론적 일관성 높음
주요도 | 토픽 모델링 기법이 얼마나 빠르게 수렴하는지 확인할 때,<br> 확률 모델이 다른 모델에 비해 얼마나 개선되었는지 평가할 때,<br> 동일 모델 내 파라미터에 따른 성능 평가할 때 주로 사용| 해당 모델이 얼마나 실제로 의미있는 결과를 내는지<br> 확인하기 위해 사용 
한계 | Perplexity가 낮다고 해서, 결과가 해석 용이하다는 의미가 아님 | 평가를 진행하기 위해 다른 외부 데이터(코퍼스, 시소러스 등)가 필요

>> [참고.1](https://bab2min.tistory.com/587)<br>
>>[참고.2](https://coredottoday.github.io/2018/09/17/%EB%AA%A8%EB%8D%B8-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D/)




- **Coherence** - 값이 높을수록 좋다
    - Coherence가 높을수록 일관성은 높아지지만, 단조로워지는 경향이 있음.


```
coherence_values = []

for i in range(2,16):
    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = i, id2word=dictionary)
    coherence_model_lda = CoherenceModel(model = ldamodel, texts = high_score_reviews, dictionary = dictionary, topn=10)
    coherence_lda = coherence_model_lda.get_coherence()
    coherence_values.append(coherence_lda)
    
```


- Coherence 그래프 그리기

```
x=range(2,16)    
plt.plot(x, coherence_values)
plt.xlabel('number of topics')
plt.ylabel('coherence score') # coherence score가 가장 높은 값을 보이는 구간 찾아 최적화된 토픽 개수 선정
plt.show()
```



- **Perplexity** - 값이 낮을수록 좋다
  - 사람이 해석하기 좋다는 의미는 아님.

```
perplexity_values = []
for i in range(2,16):
    ldamodel=gensim.models.ldamodel.LdaModel(corpus, num_topics = i, id2word = dictionary)
    perplexity_values.append(ldamodel.log_perplexity(corpus))
```


- Preplexity 그래프 그리기

```
x=range(2,16)
plt.plot(x, perplexity_values)
plt.xlabel('number of topics')
plt.ylabel('perplexity score') # perplexity score가 가장 낮은 값을 보이는 구간 찾아 최적화된 토픽 개수 선정
plt.show()
```

## #LDA 모델 학습

```
ldamodel=gensim.models.ldamodel.LdaModel(corpus, num_topics = 12, id2word = dictionary, alpha=0.01, eta=0.1, passes=30)

ldamodel.print_topics(num_words=10)
```

- 패키지 불러오기

```
import pyLDAvis
import pyLDAvis.gensim_models
```

- 시각화

```
pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)
```

- HTML로 저장하기 및 확인

```
pyLDAvis.save_html(vis, '저장할 파일명.html')

vis
```